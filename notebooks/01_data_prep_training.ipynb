{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# OpenNILM - Data Preparation & Training (PyTorch)\n\nThis notebook covers:\n1. **Data Preparation**: Loading and preprocessing NILM datasets (REFIT/PLEGMA)\n2. **Model Configuration**: Setting up CNN, GRU, or TCN models\n3. **Training**: Training the model with early stopping and checkpointing\n4. **Visualization**: Training curves and model analysis\n\n---\n\n## Google Colab Setup\n\n**If running on Colab:**\n1. Upload your `OpenNILM` folder to Google Drive (e.g., `My Drive/OpenNILM/`)\n2. Run the Colab setup cells below first\n3. Edit `DRIVE_PROJECT_PATH` to match your folder location\n\n---"
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# COLAB SETUP - Run this cell first!\n# ============================================================================\nimport sys\n\n# Detect if running on Google Colab\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    # Mount Google Drive\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \n    # Install dependencies\n    !pip install -q hydra-core omegaconf\n    \n    # =========================================================================\n    # CONFIGURE YOUR GOOGLE DRIVE PATH HERE\n    # =========================================================================\n    DRIVE_PROJECT_PATH = '/content/drive/MyDrive/OpenNILM'  # <-- EDIT THIS PATH\n    # =========================================================================\n    \n    import os\n    from pathlib import Path\n    \n    project_root = Path(DRIVE_PROJECT_PATH)\n    \n    if not project_root.exists():\n        print(f\"ERROR: Project folder not found at: {project_root}\")\n        print(f\"Please upload OpenNILM to Google Drive or edit DRIVE_PROJECT_PATH above\")\n        print(f\"\\nYour Drive contents:\")\n        !ls \"/content/drive/MyDrive/\" | head -15\n    else:\n        os.chdir(project_root)\n        sys.path.insert(0, str(project_root))\n        print(f\"Project root: {project_root}\")\n        print(f\"Working directory: {os.getcwd()}\")\nelse:\n    import os\n    from pathlib import Path\n    project_root = Path(os.getcwd()).parent\n    sys.path.insert(0, str(project_root))\n    print(f\"Running locally. Project root: {project_root}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# IMPORTS (os, sys, Path, project_root already defined in Colab setup cell)\n# ============================================================================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n# PyTorch NILM modules\nfrom src_pytorch import (\n    CNN_NILM, GRU_NILM, TCN_NILM, get_model,\n    SimpleNILMDataLoader,\n    Trainer, EarlyStopping, ModelCheckpoint, TrainingHistory,\n    set_seeds, get_device, count_parameters, print_model_summary,\n    # Config\n    MODEL_CONFIGS, TRAINING, get_appliance_params, get_model_config\n)\n\n# Set style for plots\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(42)\n",
    "\n",
    "# Get device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Configure the experiment parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# USER CONFIGURATION - Modify these values only\n# ============================================================================\nDATASET_NAME = 'plegma'      # 'refit' or 'plegma'\nAPPLIANCE_NAME = 'boiler'    # REFIT: dishwasher, washing_machine, kettle, microwave, refrigerator\n                             # PLEGMA: ac_1, boiler, washing_machine, fridge\nMODEL_NAME = 'cnn'           # 'cnn', 'gru', or 'tcn'\n\n# ============================================================================\n# AUTO-LOADED FROM CONFIG (src_pytorch/config.py) - Don't modify below\n# ============================================================================\n# Get model configuration\nmodel_config = get_model_config(MODEL_NAME)\nINPUT_WINDOW_LENGTH = model_config['input_window_length']\nBATCH_SIZE = model_config['batch_size']\n\n# Get appliance parameters\nappliance_params = get_appliance_params(DATASET_NAME, APPLIANCE_NAME)\nTHRESHOLD = appliance_params['threshold']\nCUTOFF = appliance_params['cutoff']\nAGG_MEAN = appliance_params['mean']\nAGG_STD = appliance_params['std']\n\n# Get training parameters\nEPOCHS = TRAINING['epochs']\nLEARNING_RATE = TRAINING['learning_rate']\nEARLY_STOPPING_PATIENCE = TRAINING['early_stopping_patience']\n\n# Paths\nDATA_DIR = project_root / 'data' / 'processed' / DATASET_NAME / APPLIANCE_NAME\nOUTPUT_DIR = project_root / 'outputs' / f'{MODEL_NAME}_{APPLIANCE_NAME}'\n\n# Create output directories\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n(OUTPUT_DIR / 'checkpoint').mkdir(exist_ok=True)\n(OUTPUT_DIR / 'tensorboard').mkdir(exist_ok=True)\n(OUTPUT_DIR / 'figures').mkdir(exist_ok=True)\n\n# Print configuration summary\nprint(\"=\" * 60)\nprint(\"CONFIGURATION\")\nprint(\"=\" * 60)\nprint(f\"Dataset:           {DATASET_NAME}\")\nprint(f\"Appliance:         {APPLIANCE_NAME}\")\nprint(f\"Model:             {MODEL_NAME}\")\nprint(f\"Window length:     {INPUT_WINDOW_LENGTH}\")\nprint(f\"Batch size:        {BATCH_SIZE}\")\nprint(f\"Epochs:            {EPOCHS}\")\nprint(f\"Learning rate:     {LEARNING_RATE}\")\nprint(f\"Threshold:         {THRESHOLD} W\")\nprint(f\"Cutoff:            {CUTOFF} W\")\nprint(f\"Data directory:    {DATA_DIR}\")\nprint(f\"Output directory:  {OUTPUT_DIR}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "### 3.1 Load Raw Data (Optional - For Data Exploration)\n",
    "\n",
    "If you need to process raw data first, run the data processing script:\n",
    "```bash\n",
    "cd data\n",
    "python data.py dataset=refit appliance=dishwasher\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if processed data exists\n",
    "if not DATA_DIR.exists():\n",
    "    print(f\"Warning: Data directory does not exist: {DATA_DIR}\")\n",
    "    print(\"Please run the data processing script first.\")\n",
    "else:\n",
    "    print(f\"Data directory found: {DATA_DIR}\")\n",
    "    print(f\"Files: {list(DATA_DIR.glob('*.csv'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Explore the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the training data\n",
    "train_df = pd.read_csv(DATA_DIR / 'training_.csv')\n",
    "val_df = pd.read_csv(DATA_DIR / 'validation_.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'test_.csv')\n",
    "\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Validation data shape:\", val_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"\\nColumn names:\", train_df.columns.tolist())\n",
    "print(\"\\nTraining data statistics:\")\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample of the data\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "sample_size = min(10000, len(train_df))\n",
    "sample = train_df.iloc[:sample_size]\n",
    "\n",
    "axes[0].plot(sample.iloc[:, 0], label='Aggregate Power (normalized)', alpha=0.8)\n",
    "axes[0].set_ylabel('Normalized Power')\n",
    "axes[0].set_title('Aggregate Power')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(sample.iloc[:, 1], label=f'{APPLIANCE_NAME} Power (normalized)', alpha=0.8, color='orange')\n",
    "axes[1].set_ylabel('Normalized Power')\n",
    "axes[1].set_xlabel('Sample Index')\n",
    "axes[1].set_title(f'{APPLIANCE_NAME} Power')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'figures' / 'data_visualization.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "data_loader = SimpleNILMDataLoader(\n",
    "    data_dir=str(DATA_DIR),\n",
    "    model_name=MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    input_window_length=INPUT_WINDOW_LENGTH,\n",
    "    train=True,\n",
    "    num_workers=0  # Set to > 0 for parallel data loading\n",
    ")\n",
    "\n",
    "# Get data loaders\n",
    "train_loader = data_loader.train\n",
    "val_loader = data_loader.val\n",
    "test_loader = data_loader.test\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Check a batch\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(f\"\\nBatch X shape: {batch_x.shape}\")\n",
    "print(f\"Batch Y shape: {batch_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "if MODEL_NAME == 'cnn':\n",
    "    model = CNN_NILM(input_window_length=INPUT_WINDOW_LENGTH)\n",
    "elif MODEL_NAME == 'gru':\n",
    "    model = GRU_NILM(input_window_length=INPUT_WINDOW_LENGTH)\n",
    "elif MODEL_NAME == 'tcn':\n",
    "    model = TCN_NILM(\n",
    "        input_window_length=INPUT_WINDOW_LENGTH,\n",
    "        depth=model_config.get('depth', 9),\n",
    "        nb_filters=model_config.get('nb_filters'),\n",
    "        dropout=model_config.get('dropout', 0.1),\n",
    "        stacks=model_config.get('stacks', 1)\n",
    "    )\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel: {MODEL_NAME.upper()}\")\n",
    "print(f\"Trainable parameters: {count_parameters(model):,}\")\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_input = batch_x[:2].to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"Test input shape: {test_input.shape}\")\n",
    "    print(f\"Test output shape: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Setup callbacks\n",
    "trainer.setup_callbacks(\n",
    "    checkpoint_dir=str(OUTPUT_DIR / 'checkpoint'),\n",
    "    tensorboard_dir=str(OUTPUT_DIR / 'tensorboard'),\n",
    "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "    early_stopping_min_delta=1e-6\n",
    ")\n",
    "\n",
    "print(\"Trainer configured successfully!\")\n",
    "print(f\"Checkpoint will be saved to: {OUTPUT_DIR / 'checkpoint' / 'model.pt'}\")\n",
    "print(f\"TensorBoard logs will be saved to: {OUTPUT_DIR / 'tensorboard'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 170/23167 [02:47<6:18:43,  1.01it/s, loss=0.00359]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting training for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m epochs...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m history = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining completed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\OneDrive - Accenture\\Desktop\\OpenNILM\\src_pytorch\\trainer.py:375\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs, verbose)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28mself\u001b[39m.current_epoch = epoch\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m train_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m    378\u001b[39m val_metrics = \u001b[38;5;28mself\u001b[39m.validate_epoch(val_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\OneDrive - Accenture\\Desktop\\OpenNILM\\src_pytorch\\trainer.py:282\u001b[39m, in \u001b[36mTrainer.train_epoch\u001b[39m\u001b[34m(self, train_loader)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Ensure shapes match for loss calculation\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs.shape != batch_y.shape:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\OneDrive - Accenture\\Desktop\\OpenNILM\\src_pytorch\\models\\cnn.py:96\u001b[39m, in \u001b[36mCNN_NILM.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m x.dim() == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x.shape[-\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# (batch, seq_len, 1) -> (batch, 1, seq_len)\u001b[39;00m\n\u001b[32m     94\u001b[39m     x = x.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\container.py:253\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\s.athanasoulias\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\functional.py:1441\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1442\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(f\"\\nStarting training for {EPOCHS} epochs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = trainer.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history.epochs, history.train_loss, label='Training Loss', marker='o', markersize=3)\n",
    "axes[0].plot(history.epochs, history.val_loss, label='Validation Loss', marker='o', markersize=3)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE plot\n",
    "if history.train_mae:\n",
    "    axes[1].plot(history.epochs, history.train_mae, label='Training MAE', marker='o', markersize=3)\n",
    "    axes[1].plot(history.epochs, history.val_mae, label='Validation MAE', marker='o', markersize=3)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].set_title('Training and Validation MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'figures' / 'training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print best results\n",
    "best_epoch = np.argmin(history.val_loss)\n",
    "print(f\"\\nBest epoch: {best_epoch + 1}\")\n",
    "print(f\"Best validation loss: {history.val_loss[best_epoch]:.6f}\")\n",
    "print(f\"Best validation MAE: {history.val_mae[best_epoch]:.6f}\" if history.val_mae else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_df = pd.DataFrame({\n",
    "    'epoch': history.epochs,\n",
    "    'train_loss': history.train_loss,\n",
    "    'val_loss': history.val_loss,\n",
    "    'train_mae': history.train_mae,\n",
    "    'val_mae': history.val_mae\n",
    "})\n",
    "history_df.to_csv(OUTPUT_DIR / 'training_history.csv', index=False)\n",
    "print(f\"Training history saved to: {OUTPUT_DIR / 'training_history.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Best Model and Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model checkpoint\n",
    "checkpoint_path = OUTPUT_DIR / 'checkpoint' / 'model.pt'\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick evaluation on validation set\n",
    "@torch.no_grad()\n",
    "def quick_evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_x, batch_y in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        outputs = model(batch_x)\n",
    "        \n",
    "        if outputs.shape != batch_y.shape:\n",
    "            if outputs.dim() == 2 and batch_y.dim() == 1:\n",
    "                batch_y = batch_y.unsqueeze(1)\n",
    "        \n",
    "        loss = nn.MSELoss()(outputs, batch_y)\n",
    "        mae = torch.mean(torch.abs(outputs - batch_y))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_mae += mae.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches, total_mae / num_batches\n",
    "\n",
    "val_loss, val_mae = quick_evaluate(model, val_loader, device)\n",
    "test_loss, test_mae = quick_evaluate(model, test_loader, device)\n",
    "\n",
    "print(f\"Validation - Loss: {val_loss:.6f}, MAE: {val_mae:.6f}\")\n",
    "print(f\"Test - Loss: {test_loss:.6f}, MAE: {test_mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "Training is complete! The model has been saved to the checkpoint directory.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Open `02_evaluation.ipynb` for detailed evaluation and visualization\n",
    "2. Launch TensorBoard to view training logs:\n",
    "   ```bash\n",
    "   tensorboard --logdir outputs/{model}_{appliance}/tensorboard\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Appliance: {APPLIANCE_NAME}\")\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Total parameters: {count_parameters(model):,}\")\n",
    "print(f\"Epochs trained: {len(history.epochs)}\")\n",
    "print(f\"Best validation loss: {min(history.val_loss):.6f}\")\n",
    "print(f\"Test loss: {test_loss:.6f}\")\n",
    "print(f\"Test MAE: {test_mae:.6f}\")\n",
    "print(f\"\\nCheckpoint saved to: {checkpoint_path}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}